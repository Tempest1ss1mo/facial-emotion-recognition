{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Baseline CNN Training\n",
    "\n",
    "This notebook trains a baseline CNN (LeNet-inspired) for facial emotion recognition.\n",
    "\n",
    "## Contents\n",
    "1. Setup and configuration\n",
    "2. Load data\n",
    "3. Build model\n",
    "4. Train model\n",
    "5. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.models import BaselineCNN\n",
    "from src.data import get_dataloaders\n",
    "from src.utils.metrics import MetricsTracker, calculate_metrics\n",
    "from src.utils.visualization import plot_training_history, plot_confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "CONFIG = {\n",
    "    'data_dir': '../data',\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 4,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'dropout': 0.5,\n",
    "    'num_classes': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    data_dir=CONFIG['data_dir'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')\n",
    "print(f'Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineCNN(\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nTotal parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1)\n",
    "\n",
    "# Metrics tracker\n",
    "tracker = MetricsTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    print(f'\\nEpoch {epoch}/{CONFIG[\"epochs\"]}')\n",
    "    print('-' * 30)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    tracker.update(epoch, train_loss, train_acc, val_loss, val_acc, lr)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), '../checkpoints/baseline_best.pth')\n",
    "        print(f'New best model saved! Val Acc: {val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(tracker.get_history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "model.load_state_dict(torch.load('../checkpoints/baseline_best.pth'))\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'\\nTest Results:')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
